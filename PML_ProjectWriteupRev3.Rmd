---
title: "Reproducible Research: Peer Assessment 1"
author: DJR
output:
  html_document: 
    fig.keep: all
    fig.path: figure/
    keep_md: yes
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
```

##Session Information  
**Created:** `r date()`  
**Rstudio Version:** 1.1.453 <http://www.rstudio.com> 

# Load libraries
```{r libraries, message= FALSE}
library(ggplot2);library(dplyr);library(lubridate);library(caret);library(RANN);library(PerformanceAnalytics)
#library(MASS)
```
# Summary

* Linear and Quadratic Discriminant Analysis (**LDA, QDA**) models for classifying the form in which a dumbell lifting excercise were trained using data from instruments.A training data set for six individuals is available. The instruments were placed on the belt, forearm, arm, and dumbell. Five classes are defined for characterizing qualitative activity recognition.
* The original paper associated to this data:<http://web.archive.org/web/20170519033209/http://groupware.les.inf.puc-rio.br:80/public/papers/2013.Velloso.QAR-WLE.pdf>, used a bagged random forest approach that achieved 78.2% overall accuracy. This is a good benchmark for the model used here.
* Attempted fitting a model using the **treebag** method but aborted teh training as it was not converging. QDA is less of a "brute force" approach to implementing a classfier, and convergence is much faster. 
  
* Cross-validation is used to asses the generality of the model fit.  
* The expected out of sample error prediction for the model is calculated.  

# Load Dataset
Initial inspection of the dataframe summary (not shown here for brevity) reveals a large number of divide by zero entries. These are reassigned as NA entries before further cleanup of the data.
``` {r load, cache=TRUE }
na_strings<-c("#DIV/0!","NA")
training <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", na.strings=na_strings)
testing <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", na.strings=na_strings)

```

##Data Cleanup
A few columns are reassigned apprporate classes as factors or POSIXct. Near zero variance columns that will contribute little to explaining the outcome are removed.
``` {r dataCleanup, cache=TRUE, dependson=c("load")}

trainingClean<-mutate(training, user_name=as.factor(user_name),classe=as.factor(classe),new_window=as.factor(new_window),cvtd_timestamp=dmy_hm(cvtd_timestamp))
testingClean<-mutate(testing,user_name=as.factor(user_name),new_window=as.factor(new_window),cvtd_timestamp=dmy_hm(cvtd_timestamp))
trainingClean <- trainingClean[,-nearZeroVar(trainingClean)] #remove columns with near zero variance in the TRAINING set.

```

# Exploratory Analysis
##Factors' representation in training data 
``` {r factors, cache=TRUE, dependson=c("dataCleanup")}
table(trainingClean$user_name,trainingClean$classe)
cleanColumns<-dim(trainingClean)[2]
cleanRows<-dim(trainingClean)[1]
#testRows<-dim(testingClean)[1]
```
* Seems like the data is reasonably balanced among factors. Random sampling shuold be suitable for splitting the data for cross validation purposes.  
* It is not practical to look at correlation plots since there are `r format(cleanColumns,digits=0, nsmall=0)` columns in the cleaned-up data. 

## Outcome correlation with Participant and Timestamp

``` {r corrChart, cache=TRUE, dependson=c("dataCleanup")}
sub<-select(trainingClean, user_name,raw_timestamp_part_1,raw_timestamp_part_2,classe)
sub<-mutate(sub,user_name=as.integer(user_name), classe=as.integer(classe))
suppressWarnings(chart.Correlation(sub, histogram=TRUE, pch=19))


```

* No apparent correlation exists between the outcome, participant, and the time stamp. However, the model should only use instrument motion data to classify the outcome. Therefore, the timestamp columns and participant factor should be excluded form the cleaned-up training set.  
* Since the cleaned up columns (except for factors and timestamps) are numerical, model-based linear classification methods  seem appropriate. These methods assume multivariate **Gaussian** parameters with same covariances (**LDA**) or different covariances(**QDA**). 
* To fulfill the Gaussian assumption **standardizing (center and scale) + BoxCox** preprocessing is used.  
* Since there is missing data in many columns, **nearest neighbors inpute** is used.
* Since we have a reasonably large size of well-balanced training cases (`r format(cleanRows,digits=0, nsmall=0)` rows), a **single cross-validation set** can be randomly sampled from it to **estimate out of sample error**. 

``` {r preprocessingR, cache=TRUE, dependson=c("dataCleanup")}
set.seed(7986)

#Remove timestamp columns and participant factor
trainingPre<-select(trainingClean,-X,-user_name,-classe, -raw_timestamp_part_1,-raw_timestamp_part_2, -cvtd_timestamp)

#Create pre-processing object
#PreObj_StdBoxCox<-preProcess(trainingPre,method = c("center","scale","BoxCox", 'knnImpute'))
PreObj_StdBoxCox<-preProcess(trainingPre,method = c('knnImpute'))
#Preprocess
trainingPre <- predict(PreObj_StdBoxCox, newdata=trainingPre) #pre-processed parameters
trainingPre <-mutate(trainingPre, classe=training$classe) #restore outcome column
#Split data for cross-validation
#trainp<-0.75
#pcntCV<-(1-0.75)*100
#inTrain<-createDataPartition(trainingPre$classe,p=trainp,list=FALSE)
#training<-trainingPre[inTrain,]
#crossValidation<-trainingPre[-inTrain,]
#ARtraining<-dim(training)[1]/dim(training)[2]
ARtraining<-dim(trainingPre)[1]/dim(trainingPre)[2]


#* `r format(pcntCV,digits=0, nsmall=0)`% of the original training data is split for use as a cross-validation #set. No need for other resampling methods (e.g. k-fold) since the data set is not small. A judgement call is #made in favor of less variance (potentially larger prediction bias). 
#rm(trainingClean)
```
* We have over 10 times (`r format(ARtraining,digits=0, nsmall=0)`) more sample rows than predictor columns, as recommeded for the QDA covariance matrix to be invertible.

# Training
* Fitted a **LDA and QDA** models with preprocessing combining **center,scale, BoxCox, and PCA**. Training converged in less than a minute using a typical laptop PC.   
* Also tried training a model using the **treebag** method which did not converge within many minutes of runtime.
* Used 10 fold Cross-Validation resampling to assess the **out of sample error** and **kappa** metric.
* PCA is used to distill a regressor basis that captures most of the variance with optimum degrees of freedom.
* LDA expected performance is better but warnings of **collinearity** were present during the training. QDA converged with no warnings.
* 

## LDA Training
``` {r LDATrain, cache=TRUE, dependson=c("preprocessingR")}
#priorClasse<-c(1, 1, 1, 1, 1)/5 #Assume prior probabilities for excercise outcome (classe)
set.seed(342)

suppressWarnings(fitLDA<-train(classe~.,data=trainingPre,method="lda",preProcess=c("center","scale"),trControl = trainControl(method = "cv"))) #accuracy 0.7646 kappa 0.7023
print(fitLDA)
confusionMatrix(data=predict(fitLDA,trainingPre),reference=trainingPre$classe)
predLDAtraining<-predict(fitLDA,trainingPre)
```

## QDA TRAINING
```{r QDATrain,cache=TRUE, dependson=c("preprocessingR")}
fitQDA<-train(classe~.,data=trainingPre,method="qda",preProcess=c("center","scale","pca"),trControl = trainControl(method = "cv")) #accuracy 0.7498 kappa 0.6870
print(fitQDA)
confusionMatrix(data=predict(fitQDA,trainingPre),reference=trainingPre$classe)
predQDAtraining<-predict(fitQDA,trainingPre)
```

## Combined Model
The LDA and QDA predictions could be used in a combineed model for better acccuracy but the benefit will be marginal since the predictions are highly correlated (see plot below):
``` {r combinedMOdel, cache=TRUE, dependson=c("LDATrain","QDATrain","preprocessingR")}
qplot(predLDAtraining,predQDAtraining,colour=classe, data=trainingPre,geom="jitter")
```

## Treebag Training (failed to converge)
```{r TBTrain,cache=TRUE, dependson=c("preprocessingR")}
#fitTB<-train(classe~.,data=trainingPre,method="treebag",preProcess=c("center","scale","BoxCox","pca")) #failed to converge
```



